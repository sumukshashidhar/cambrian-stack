# Training defaults for diffusion transformer
device_batch_size: 24
total_batch_size: 262144
max_steps: 10000
learning_rate: 3.0e-4
weight_decay: 0.01
grad_clip: 1.0
warmup_ratio: 0.01
warmdown_ratio: 0.2
final_lr_frac: 0.1
eval_every: 250
eval_batches: 20
sample_every: 1000
save_every: 2500
